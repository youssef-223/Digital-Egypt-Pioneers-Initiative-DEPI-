import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random
import subprocess
from google.colab import files
import os
from sklearn.impute import SimpleImputer



# Usage:
# setup_kaggle_competition('microsoft-malware-prediction')
def setup_kaggle_competition(competition_name, kaggle_json='kaggle.json'):
    # Define paths
    kaggle_json_path = os.path.join(os.getcwd(), kaggle_json)
    kaggle_dir = os.path.expanduser('~/.kaggle')
    kaggle_json_dest = os.path.join(kaggle_dir, kaggle_json)

    # Step 1: Check if 'kaggle.json' exists in the current directory
    if not os.path.isfile(kaggle_json_path):
        print(f"'{kaggle_json}' not found in the current directory.")
        print("Please upload your 'kaggle.json' file.")
        uploaded = files.upload()
        
        # Verify upload
        if kaggle_json not in uploaded:
            raise FileNotFoundError(f"{kaggle_json} was not uploaded.")
        
        # Move the uploaded file to the correct location
        os.rename(kaggle_json, kaggle_json_path)
    
    # Step 2: Create Kaggle directory if it does not exist and move 'kaggle.json'
    if not os.path.exists(kaggle_dir):
        os.makedirs(kaggle_dir)
    
    # Move the Kaggle JSON file to the Kaggle directory
    if not os.path.isfile(kaggle_json_dest):
        os.rename(kaggle_json_path, kaggle_json_dest)
        os.chmod(kaggle_json_dest, 0o600)
        print(f"Moved '{kaggle_json}' to '{kaggle_dir}'.")

    # Step 3: Download the competition dataset
    print(f"Downloading competition data for '{competition_name}' from Kaggle.")
    result = subprocess.run(['kaggle', 'competitions', 'download', '-c', competition_name],
                            capture_output=True, text=True)
    if result.returncode != 0:
        print(f"Error downloading data: {result.stderr}")
        return
    
    print("Download successful.")

    # Step 4: Unzip the dataset
    zip_file = f"{competition_name}.zip"
    if os.path.exists(zip_file):
        print(f"Unzipping the '{zip_file}' file.")
        result = subprocess.run(['unzip', zip_file], capture_output=True, text=True)
        if result.returncode != 0:
            print(f"Error unzipping file: {result.stderr}")
        else:
            print("Unzip successful.")
    else:
        print(f"Zip file '{zip_file}' not found.")

# Usage
# random_sample = load_random_sample('train.csv', sample_size=10000)

def load_random_sample(file_path, sample_size=10000):
    # Get the number of rows in the file
    row_count = sum(1 for _ in open(file_path)) - 1  # Subtract 1 to account for the header
    
    # Generate random row numbers to skip (to achieve random sampling)
    skip_rows = sorted(random.sample(range(1, row_count + 1), row_count - sample_size))
    
    # Load the sample (skip the randomly selected rows)
    random_sample = pd.read_csv(file_path, skiprows=skip_rows)
    
    # Return the random sample
    return random_sample


def clean_and_impute_data(df, cat_features_idx, num_features_idx):
    # Calculate the percentage of missing values for each feature
    missing_percentage = (df.isnull().sum() / len(df)) * 100

    # Identify features with more than 50% missing values
    features_to_drop = missing_percentage[missing_percentage > 50].index

    # Drop the features with more than 50% missing values
    df_cleaned = df.drop(columns=features_to_drop)

    # Print the names of the dropped features
    print("Dropped features with more than 50% missing values:")
    print(features_to_drop.tolist())

    # Identify categorical and numerical features
    cat_features = df_cleaned.columns[cat_features_idx]
    num_features = df_cleaned.columns[num_features_idx]

    # Impute missing values for categorical features with mode
    imputer_cat = SimpleImputer(strategy='most_frequent')
    df_cleaned[cat_features] = imputer_cat.fit_transform(df_cleaned[cat_features])

    # Impute missing values for numerical features with mean
    imputer_num = SimpleImputer(strategy='mean')
    df_cleaned[num_features] = imputer_num.fit_transform(df_cleaned[num_features])

    # Display the cleaned DataFrame shape for confirmation
    print(f"New DataFrame shape: {df_cleaned.shape}")

    return df_cleaned


def plot_numerical_features(data, features_per_row=5):
    numerical_data = data.select_dtypes(include=['int64', 'float64'])
    num_features = len(numerical_data.columns)
    
    num_rows = (num_features + features_per_row - 1) // features_per_row
    
    for row in range(num_rows):
        start_col = row * features_per_row
        end_col = min(start_col + features_per_row, num_features)
        cols_to_plot = numerical_data.columns[start_col:end_col]
        
        fig, axes = plt.subplots(1, len(cols_to_plot), figsize=(20, 5))  # Increased figure width
        if len(cols_to_plot) == 1:
            axes = [axes]  # Ensure axes is iterable if only one subplot
        
    for i, col in enumerate(cols_to_plot):
        sns.histplot(numerical_data[col], kde=True, ax=axes[i])
        axes[i].set_title(f'Distribution of {col}', fontsize=12)
        axes[i].tick_params(axis='x', rotation=45)  # Rotate x-axis labels for better readability
        
        plt.tight_layout()
        plt.show()

        
def get_categorical_columns_with_few_unique_values(df, max_unique=10):
    # Initialize a list to hold column names
    categorical_columns = []

    # Iterate over columns to check unique values
    for column in df.select_dtypes(include=['object', 'category']).columns:
        unique_values = df[column].unique()
        num_unique = len(unique_values)
        if num_unique < max_unique:
            categorical_columns.append(column)
    
    # Print the results
    print("Categorical columns with fewer than", max_unique, "unique values:")
    for column in categorical_columns:
        unique_values = df[column].unique()
        print(f"Column: '{column}'")
        print(f"Number of unique values: {len(unique_values)}")
        print(f"Unique values: {unique_values}")
        print("-" * 100, "\n")
    
    return categorical_columns

