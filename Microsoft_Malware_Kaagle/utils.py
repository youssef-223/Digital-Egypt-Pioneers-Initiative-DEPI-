import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random
import subprocess
from IPython.display import display
from google.colab import files
import os
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder



# Usage:
# setup_kaggle_competition('microsoft-malware-prediction')
def setup_kaggle_competition(competition_name, kaggle_json='kaggle.json'):
    # Define paths
    kaggle_json_path = os.path.join(os.getcwd(), kaggle_json)
    kaggle_dir = os.path.expanduser('~/.kaggle')
    kaggle_json_dest = os.path.join(kaggle_dir, kaggle_json)

    # Step 1: Check if 'kaggle.json' exists in the current directory
    if not os.path.isfile(kaggle_json_path):
        print(f"'{kaggle_json}' not found in the current directory.")
        print("Please upload your 'kaggle.json' file.")
        uploaded = files.upload()
        
        # Verify upload
        if kaggle_json not in uploaded:
            raise FileNotFoundError(f"{kaggle_json} was not uploaded.")
        
        # Move the uploaded file to the correct location
        os.rename(kaggle_json, kaggle_json_path)
    
    # Step 2: Create Kaggle directory if it does not exist and move 'kaggle.json'
    if not os.path.exists(kaggle_dir):
        os.makedirs(kaggle_dir)
    
    # Move the Kaggle JSON file to the Kaggle directory
    if not os.path.isfile(kaggle_json_dest):
        os.rename(kaggle_json_path, kaggle_json_dest)
        os.chmod(kaggle_json_dest, 0o600)
        print(f"Moved '{kaggle_json}' to '{kaggle_dir}'.")

    # Step 3: Download the competition dataset
    print(f"Downloading competition data for '{competition_name}' from Kaggle.")
    result = subprocess.run(['kaggle', 'competitions', 'download', '-c', competition_name],
                            capture_output=True, text=True)
    if result.returncode != 0:
        print(f"Error downloading data: {result.stderr}")
        return
    
    print("Download successful.")

    # Step 4: Unzip the dataset
    zip_file = f"{competition_name}.zip"
    if os.path.exists(zip_file):
        print(f"Unzipping the '{zip_file}' file.")
        result = subprocess.run(['unzip', zip_file], capture_output=True, text=True)
        if result.returncode != 0:
            print(f"Error unzipping file: {result.stderr}")
        else:
            print("Unzip successful.")
    else:
        print(f"Zip file '{zip_file}' not found.")

# Usage
# random_sample = load_random_sample('train.csv', sample_size=10000, random_seed=42)

def load_random_sample(file_path, sample_size=10000, random_seed=None):
    # Set the random seed if provided
    if random_seed is not None:
        random.seed(random_seed)
    
    # Get the number of rows in the file
    row_count = sum(1 for _ in open(file_path)) - 1  # Subtract 1 to account for the header
    
    # Generate random row numbers to skip (to achieve random sampling)
    skip_rows = sorted(random.sample(range(1, row_count + 1), row_count - sample_size))
    
    # Load the sample (skip the randomly selected rows)
    random_sample = pd.read_csv(file_path, skiprows=skip_rows)
    
    # Return the random sample
    return random_sample



def null_summary(df):
    # Create the DataFrame with missing values summary
    missing_values_summary = pd.DataFrame({
        'Total No. of Missing Values': df.isnull().sum(),
        'Percentage of Missing Values': (df.isnull().sum() / len(df)) * 100
    })

    # Display the DataFrame
    display(missing_values_summary)


def clean_and_impute_data(df, cat_cols, num_cols):

    # Calculate the percentage of missing values for each feature
    missing_percentage = (df.isnull().sum() / len(df)) * 100

    # Identify features with more than 50% missing values
    features_to_drop = missing_percentage[missing_percentage > 50].index

    # Drop the features with more than 50% missing values
    df_cleaned = df.drop(columns=features_to_drop)

    # Print the names of the dropped features
    print("Dropped features with more than 50% missing values:")
    print(features_to_drop.tolist())

    # Update cat_cols and num_cols by removing the dropped features
    cat_cols = [col for col in cat_cols if col not in features_to_drop]
    num_cols = [col for col in num_cols if col not in features_to_drop]
    
    # Impute missing values for categorical features with mode
    imputer_cat = SimpleImputer(strategy='most_frequent')
    df_cleaned[cat_cols] = imputer_cat.fit_transform(df_cleaned[cat_cols])

    # Impute missing values for numerical features with mean
    imputer_num = SimpleImputer(strategy='mean')
    df_cleaned[num_cols] = imputer_num.fit_transform(df_cleaned[num_cols])

    # Display the old shape of the Dataframe for clarrification
    print(f"\nOriginal DataFrame shape: {df.shape}")
    # Display the cleaned DataFrame shape for confirmation
    print(f"New DataFrame shape: {df_cleaned.shape}")

    return df_cleaned, cat_cols, num_cols



def plot_numerical_features(data, features_per_row=5):
    numerical_data = data.select_dtypes(include=['int64', 'float64'])
    num_features = len(numerical_data.columns)
    
    num_rows = (num_features + features_per_row - 1) // features_per_row
    
    for row in range(num_rows):
        start_col = row * features_per_row
        end_col = min(start_col + features_per_row, num_features)
        cols_to_plot = numerical_data.columns[start_col:end_col]
        
        fig, axes = plt.subplots(1, len(cols_to_plot), figsize=(20, 5))  # Increased figure width
        if len(cols_to_plot) == 1:
            axes = [axes]  # Ensure axes is iterable if only one subplot
        
    for i, col in enumerate(cols_to_plot):
        sns.histplot(numerical_data[col], kde=True, ax=axes[i])
        axes[i].set_title(f'Distribution of {col}', fontsize=12)
        axes[i].tick_params(axis='x', rotation=45)  # Rotate x-axis labels for better readability
        
        plt.tight_layout()
        plt.show()

        
def get_cat_cols(df, max_unique=10, show_unique_values=False):
    # Initialize sets to hold column names
    numerical_with_few_unique = set()
    all_object_columns = set()

    # Iterate over columns to check unique values
    for column in df.columns:
        # Check for numerical columns with fewer than max_unique unique values
        if pd.api.types.is_numeric_dtype(df[column]):
            num_unique = len(df[column].unique())
            if num_unique < max_unique:
                numerical_with_few_unique.add(column)
        
        # Check for object type columns
        elif pd.api.types.is_object_dtype(df[column]):
            all_object_columns.add(column)
    
    # Combine both sets into one list
    combined_columns = list(numerical_with_few_unique.union(all_object_columns))
    
    # Print the results for verification
    if show_unique_values:
        print("Numerical columns with fewer than", max_unique, "unique values:")
        for column in numerical_with_few_unique:
            unique_values = df[column].unique()
            print(f"Column: '{column}'")
            print(f"Number of unique values: {len(unique_values)}")
            print(f"Unique values: {unique_values}")
            print("-" * 100, "\n")
    
        print("All categorical columns with dtype 'object':")
        for column in all_object_columns:
            unique_values = df[column].unique()
            print(f"Column: '{column}'")
            print(f"Number of unique values: {len(unique_values)}")
            print(f"Unique values: {unique_values}")
            print("-" * 100, "\n")
    
    # Return the combined list of columns
    return combined_columns




def countplot(df, column, target):
    plt.figure(figsize=(15,5))
    ax = sns.countplot(x=column, data=df, hue=target ,palette="Set2")
    for value in ax.patches:
        percentage = "{:.1f}%".format(100*value.get_height()/len(df[column]))
        x = value.get_x() + value.get_width() / 2 - 0.05
        y = value.get_y() + value.get_height()
        ax.annotate(percentage, (x,y), fontweight="black",size=15)
        
    plt.title(f"Gamer devices by {column}",fontweight="black",size=20,pad=20)
    plt.show()


def continous_plot(df, column, target):
    plt.figure(figsize=(13,6))
    plt.subplot(1,2,1)
    sns.histplot(x=column,hue=target,data=df,kde=True,palette="Set2")
    plt.title(f"Distribution of {column} by {target} Status",fontweight="black",pad=20,size=15)

    plt.subplot(1,2,2)
    sns.boxplot(y= column,data=df,hue="Churned" ,palette="Set2")
    plt.title(f"Distribution of {column} by {target} Status",fontweight="black",pad=20,size=15)
    plt.tight_layout()
    plt.show()



def downcast_numerical(df, num_cols):
    for col in num_cols:
        if df[col].dtype in ['float64', 'int64']:  # Check if column is numerical
            df[col] = pd.to_numeric(df[col], downcast='integer')
    return df


def encode_categorical(df, cat_cols):
    label_encoders = {}
    
    for col in cat_cols:
        if col in df.columns:
            le = LabelEncoder()
            df[col] = le.fit_transform(df[col])
            label_encoders[col] = le
    
    return df
